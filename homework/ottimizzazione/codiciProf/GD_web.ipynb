{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodo di Discesa del Gradiente in Python\n",
    "\n",
    "Consideriamo per esempio la funzione in una variabile $f(x) = (x-1)^2 + e^x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f(x):\n",
    "    return (x-1) ** 2 + np.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oltre alla funzione $f(x)$, necessitiamo per l'implementazione del metodo di discesa del gradiente anche della sua derivata $f'(x)$. Attraverso dei semplici calcoli, si nota che:\n",
    "\n",
    "$$\n",
    "f'(x) = 2(x-1) + e^x.\n",
    "$$\n",
    "\n",
    "Andiamo ad implementare questa funzione in Python.\n",
    "\n",
    "```{warning}\n",
    "Come già detto, **NON** si utilizzano software di differenziazione automatica per svolgere questi esercizi (che sono poco efficienti). Si calcola invece la derivata di $f(x)$ *a mano*, e la si implementa come una funzione Python. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df(x):\n",
    "    return 2*(x-1) + np.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passiamo quindi ad implementare la funzione di Discesa del Gradiente, nella sua forma *base*. Andremo poi ad aggiungerci funzionalità in seguito.\n",
    "\n",
    "In particolare, considereremo un algoritmo che prende in input:\n",
    "* una funzione `f`;\n",
    "* la sua derivata `df`;\n",
    "* un valore iniziale `x0`;\n",
    "* un valore di learning rate `alpha` (che lo consideriamo costante);\n",
    "* un numero `maxit` di iterazioni;\n",
    "\n",
    "> Il metodo della discesa del gradiente con la scelta fatta di selezionare un valore fisso e costante del learning rate $\\alpha$, uguale per tutte le iterazioni del metodo, prende il nome di **metodo di discesa del gradiente a passo fisso**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(f, df, x0, alpha, maxit=100):\n",
    "    r\"\"\"\n",
    "    Implementa il metodo di discesa del gradiente con passo fisso applicato ad una funzione f(x) della quale si conosce la derivata df(x). \n",
    "\n",
    "    Parameters:\n",
    "    f (function): la funzione obiettivo che si vuole minimizzare\n",
    "    df (function): la derivata (o gradiente) della funzione obiettivo\n",
    "    x0 (ndarray): valore iniziale dell'algoritmo\n",
    "    alpha (float): il passo fisso che descrive gli step dell'algoritmo\n",
    "    maxit (int): numero di iterazioni\n",
    "    \"\"\"\n",
    "    # Inizializzazione\n",
    "    k = 0\n",
    "\n",
    "    # Ciclo iterativo (uso un ciclo while)\n",
    "    while k < maxit:\n",
    "        # Aggiornamento x_{k+1} = x_k - alpha_k df(x_k)\n",
    "        x = x0 - alpha * df(x0)\n",
    "\n",
    "        # Preparazione per step successivo\n",
    "        k = k + 1\n",
    "        x0 = x\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifichiamone il funzionamento sulla funzione implementata sopra, che come già osservato soluzione esatta $x^* \\approx 0.31492$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soluzione calcolata: 0.3040\n",
      "Errore Relativo della soluzione calcolata: 0.03453.\n"
     ]
    }
   ],
   "source": [
    "# Fissiamo i parametri dell'algoritmo (iperparametri)\n",
    "x0 = 0\n",
    "alpha = 1e-2\n",
    "maxit = 100\n",
    "\n",
    "# Calcoliamo la soluzione\n",
    "x_sol = GD(f, df, x0, alpha, maxit)\n",
    "print(f\"Soluzione calcolata: {x_sol:0.4f}\")\n",
    "\n",
    "# A scopo di analisi di prestazioni, misuriamo l'errore rispetto al minimo (noto)\n",
    "x_true = 0.31492\n",
    "rel_err = np.linalg.norm(x_sol - x_true) / np.linalg.norm(x_true)\n",
    "print(f\"Errore Relativo della soluzione calcolata: {rel_err:0.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Esercizio:** Valutare l'impatto del punto iniziale `x0`, dello step-size `alpha` e del numero di iterazioni `maxit` sulla soluzione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come avrete senz'altro notato, il numero di iterazioni influenza tantissimo l'errore ottenuto dall'algoritmo. Andiamo quindi a modificare l'algoritmo sopra per includere una misura dell'errore relativo tra la soluzione computata $x_k$ al passo $k$-esimo e la soluzione esatta $x_{true}$ ad ogni step, oltre che il valore della funzione obiettivo $f(x_k)$ e la norma del gradiente $|| \\nabla f(x_k) ||_2^2$, in modo da poterlo visualizzare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(f, df, x0, x_true, alpha, maxit=100):\n",
    "    r\"\"\"\n",
    "    Implementa il metodo di discesa del gradiente con passo fisso applicato ad una funzione f(x) della quale si conosce la derivata df(x). \n",
    "\n",
    "    Parameters:\n",
    "    f (function): la funzione obiettivo che si vuole minimizzare\n",
    "    df (function): la derivata (o gradiente) della funzione obiettivo\n",
    "    x0 (ndarray): valore iniziale dell'algoritmo\n",
    "    x_true (ndarray): la soluzione esatta dell'algoritmo (nota SOLO in fase di test)\n",
    "    alpha (float): il passo fisso che descrive gli step dell'algoritmo\n",
    "    maxit (int): numero di iterazioni\n",
    "    \"\"\"\n",
    "    # Inizializzazione\n",
    "    k = 0\n",
    "    rel_err = np.zeros((maxit, ))\n",
    "    obj_val = np.zeros((maxit, ))\n",
    "    grad_norm = np.zeros((maxit, ))\n",
    "\n",
    "    # Ciclo iterativo (uso un ciclo while)\n",
    "    while k < maxit:\n",
    "        # Aggiornamento x_{k+1} = x_k - alpha_k df(x_k)\n",
    "        x = x0 - alpha * df(x0)\n",
    "\n",
    "        # Calcolo dell'errore e salvataggio\n",
    "        rel_err[k] = np.linalg.norm(x - x_true) / np.linalg.norm(x_true)\n",
    "        obj_val[k] = f(x)\n",
    "        grad_norm[k] = np.linalg.norm(df(x))\n",
    "\n",
    "        # Preparazione per step successivo\n",
    "        k = k + 1\n",
    "        x0 = x\n",
    "\n",
    "    return x, rel_err, obj_val, grad_norm\n",
    "\n",
    "# Fissiamo i parametri dell'algoritmo (iperparametri)\n",
    "x0 = 0\n",
    "x_true = 0.31492\n",
    "alpha = 1e-2\n",
    "maxit = 300\n",
    "\n",
    "# Calcoliamo la soluzione\n",
    "x_sol, rel_err, obj_val, grad_norm = GD(f, df, x0, x_true, alpha, maxit)\n",
    "\n",
    "# Visualizziamo le metriche\n",
    "plt.plot(np.arange(maxit), rel_err, \"r-\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Rel. Err.\")\n",
    "plt.title(\"Rel. Err.\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(maxit), obj_val, \"r-\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.title(\"Funzione obiettivo\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(maxit), grad_norm, \"r-\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"|| df(x) ||_2\")\n",
    "plt.title(\"Norma gradiente\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteri di Arresto\n",
    "Dal grafico dell'errore appena misurato, si osserva come l'errore nella soluzione l'errore decresce dapprima molto velocemente, per poi stabilizzarsi e smettere, praticamente, di scendere. Questo comportamento evidenzia la necessità di definire un metodo **automatico** per determinare quando l'algoritmo deve essere terminato, poiché in generale non è necessario raggiungere il numero di iterazioni `maxit` selezionato.\n",
    "\n",
    "Le condizioni necessarie e sufficienti di ottimalità suggeriscono che un semplice metodo per determinare se un tale valore $x_k$ sia o meno in prossimità di un minimo è controllare il valore di $|| \\nabla f(x_k) ||_2$. Infatti, se $x_k$ fosse esattamente uguale ad un punto di minimo, allora sarebbe un punto stazionario (per via delle condizioni necessarie del primo ordine), e quindi varrebbe che $|| \\nabla f(x_k) ||_2 = 0$. Di conseguenza, possiamo immaginarci che tanto più $|| \\nabla f(x_k) ||$ è piccola, tanto più $x_k$ sarà vicino ad un punto di minimo. Questa osservazione ci porta al primo dei criteri di arresto: selezionata una tolleranza `tolf` (il cui valore dipende dall'applicazione, ma è solitamente selezionato valere attorno a $10^{-6}$), si interrompe l'algoritmo quando:\n",
    "\n",
    "$$\n",
    "|| \\nabla f(x_k) ||_2 \\leq tolf.\n",
    "$$\n",
    "\n",
    "Ma questa condizione non è sufficiente. Infatti, **se la funzione $f(x)$ è molto piatta**, è possibile che $|| \\nabla f(x_k) ||_2$ sia piccola, ma $x_k$ sia lontano dal punto di minimo. Per questo motivo, si è soliti inserire un'ulteriore condizione, definita scegliendo un parametro `tolx` (in genere attorno a $10^{-6}$), e fermando l'algoritmo quando:\n",
    "\n",
    "$$\n",
    "|| x_{k+1} - x_k ||_2 \\leq tolx.\n",
    "$$\n",
    "\n",
    "Quando succede, fermiamo l'algoritmo iterativo e ritorniamo un messaggio di errore che dice che non si è raggiunto il punto di minimo perché la funzione obiettivo era troppo piatta.\n",
    "\n",
    "Vediamo come modificare la funzione `GD` sopra per integrare queste funzionalità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(f, df, x0, x_true, alpha, maxit=100, tolf=1e-6, tolx=1e-6):\n",
    "    r\"\"\"\n",
    "    Implementa il metodo di discesa del gradiente con passo fisso applicato ad una funzione f(x) della quale si conosce la derivata df(x). \n",
    "\n",
    "    Parameters:\n",
    "    f (function): la funzione obiettivo che si vuole minimizzare\n",
    "    df (function): la derivata (o gradiente) della funzione obiettivo\n",
    "    x0 (ndarray): valore iniziale dell'algoritmo\n",
    "    x_true (ndarray): la soluzione esatta dell'algoritmo (nota SOLO in fase di test)\n",
    "    alpha (float): il passo fisso che descrive gli step dell'algoritmo\n",
    "    maxit (int): numero di iterazioni\n",
    "    tolf (float): tolleranza di || grad(f) ||_2\n",
    "    tolx (float): tolleranza di || x_{k+1} - x_k ||_2\n",
    "    \"\"\"\n",
    "    # Inizializzazione\n",
    "    k = 0\n",
    "    rel_err = np.zeros((maxit+1, ))\n",
    "    obj_val = np.zeros((maxit+1, ))\n",
    "    grad_norm = np.zeros((maxit+1, ))\n",
    "\n",
    "    # Ciclo iterativo (uso un ciclo while)\n",
    "    condizione = True\n",
    "    while condizione:\n",
    "        # Aggiornamento x_{k+1} = x_k - alpha_k df(x_k)\n",
    "        x = x0 - alpha * df(x0)\n",
    "\n",
    "        # Calcolo dell'errore e salvataggio\n",
    "        rel_err[k] = np.linalg.norm(x - x_true) / np.linalg.norm(x_true)\n",
    "        obj_val[k] = f(x)\n",
    "        grad_norm[k] = np.linalg.norm(df(x))\n",
    "\n",
    "        # Check condizioni di arresto\n",
    "        condizione = (k < maxit) and (np.linalg.norm(df(x)) > tolf) and (np.linalg.norm(x - x0) > tolx)\n",
    "\n",
    "        # Se l'algoritmo termina per || x_{k+1} - x_k || < tolx, stampare il warning\n",
    "        if (np.linalg.norm(x - x0) < tolx):\n",
    "            print(f\"Algoritmo terminato per condizione su tolx.\")\n",
    "            \n",
    "        # Preparazione per step successivo\n",
    "        k = k + 1\n",
    "        x0 = x\n",
    "\n",
    "    # Se l'algoritmo si ferma prima di maxit, tagliare i valori inutilizzati delle metriche\n",
    "    if k < maxit:\n",
    "        rel_err = rel_err[:k]\n",
    "        obj_val = obj_val[:k]\n",
    "        grad_norm = grad_norm[:k]\n",
    "\n",
    "    return x, rel_err, obj_val, grad_norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scelta del passo\n",
    "Cosa succede se il valore del passo fisso $\\alpha$ viene scelto troppo grande? Proviamo a lanciare l'algoritmo sopra con $\\alpha = 1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo di backtracing\n",
    "Ma come fare ad assicurarsi che le condizione di Wolfe vengano rispettate? Per farlo, esiste un algoritmo semplice ma estremamente efficace chiamato **algoritmo di backtracing**, il cui funzionamento è il seguente:\n",
    "\n",
    "* Si inizializza $\\alpha_k$ con una stima di partenza (in genere, $\\alpha_k = 1$);\n",
    "* Si controlla se $\\alpha_k$ soddisfa la condizione di Armijo;\n",
    "* Se si, allora l'algoritmo termina. Altrimenti, si riduce il valore di $\\alpha_k$ e si ripete dallo step precedente.\n",
    "\n",
    "Un'implementazione dell'algoritmo di backtracing è la seguente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtracking(f, df, x, alpha=1, rho=0.5, c=1e-4):\n",
    "    \"\"\"\n",
    "    Algoritmo di backtracking per Discesa Gradiente.\n",
    "\n",
    "    Parameters:\n",
    "    f       : Funzione obiettivo.\n",
    "    df      : Gradiente della funzione obiettivo.\n",
    "    x       : Iterato x_k.\n",
    "    alpha   : Stima iniziale di alpha(default 1).\n",
    "    rho     : Fattore di riduzione (default 0.5).\n",
    "    c       : Costante delle condizioni di Armijo (default 1e-4).\n",
    "\n",
    "    Returns:\n",
    "    alpha   : Learning rate calcolato con backtracking.\n",
    "    \"\"\"\n",
    "    while f(x - alpha * df(x)) > f(x) - c * alpha * np.linalg.norm(df(x))**2:\n",
    "        alpha *= rho\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E' possibile dimostrare che, se $\\alpha_k$ viene scelto tramite algoritmo di backtracking, allora necessariamente soddisferà le condizioni di Wolfe, e l'algoritmo di Discesa del Gradiente convergerà.\n",
    "\n",
    "```{warning}\n",
    "L'algoritmo di backtracing **NON** seleziona il valore migliore possibile del parametro $\\alpha_k$. Non assicura, cioè, che la funzione raggiungerà il minimo nel minor numero possibile di step. \n",
    "```\n",
    "\n",
    "Vediamo come utilizzare l'algoritmo di backtracking per trovare la soluzione di minimo al problema definito sopra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da notare come il metodo di backtracking ha un costo. Infatti, per trovare il valore del learning rate tale da soddisfare le condizioni di Armijo, è a volte necessario eseguire varie volte il ciclo che definisce l'algoritmo, che richiede a sua volta di calcolare il valore di un possibile $x_{k+1}$ per ogni dato $\\alpha_k$. Come risultato, può capitare che a livello di tempo di esecuzione, l'algoritmo con metodo di backtracking richieda molto più tempo a convergere di quanto sia necessario con scelta fissa del passo (il quale, però, non ha certezza di covergere!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Esercizio:** Confrontare su uno stesso plot il risultato ottenuto con il metodo di backtracking e differenti valori di passo fisso $\\alpha$. Commentare sul metodo migliore in questo caso. Confrontare anche il tempo richiesto da ciascun metodo a convergere."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (calcolo)",
   "language": "python",
   "name": "calcolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
